---
title: 주성분 분석(PCA)
sidebar:
  nav: docs-ko
aside:
  toc: true
key: 20190727
tags: 선형대수
---
<style>
@media screen and (max-width:500px){
  iframe {
  width: 70vw;
  height: 70vw;
  background:white;
  }
}

@media screen and (min-width:500px){
  iframe {
  width: 50vw;
  height: 50vw;
  background:white;
  }
}
</style>

<p align="center">
<center><iframe src="https://angeloyeo.github.io/p5/2019-07-27-preview_PCA/" frameborder = "0"></iframe></center>
</p>

<center>
<b>

PCA가 말하는 것: 데이터들을 정사영 시켜 차원을 낮춘다면,

어떤 축에다 데이터들을 정사영 시켜야 원래의 데이터 구조를 제일 잘 유지할 수 있을까?

</b>

</center>


# 공분산 행렬의 의미

특징 쌍(feature pairs)들이 얼마나 닮았는가를 행렬에 나타내고 있다.

## 데이터 행렬과 공분산 행렬의 유도

 이번에는 공분산 행렬에 대해 알아보도록 하자. 공분산 행렬은 2변량 이상의 변량이 있는 경우에 여러 개의 두 변량 값들 간의 공분산을 행렬로 표현한 것으로 정의하고 있다. 

가령 n 명의 사람들로부터 각각 d개의 특징(feature)을 추출했다고 하자. 그리고 이 데이터를 그림 5와 같이 행렬로 표현해보자. 그리고 이 데이터를 다음과 같이 행렬로 표현해보자. 

이 때, 아래의 행렬의 각 열(feature)들의 평균 값은 0이라고 하자.

<p align="center">
<img width = "400" src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2019-07-27_PCA/mat_x.png">
<br>
그림 X. d개의 n차원 열벡터를 쌓아서 얻은 데이터 행렬 X

</p>


이번에는 데이터 행렬 $X$를 이용해서 공분산 행렬을 나타내보려고 한다.

<p align="center">
<img width = "600" src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2019-07-27_PCA/XTX.png">
<br>
그림 X. 설명
</p>

여기서 dot($\bullet$,$\bullet$)은 두 벡터의 내적 연산을 의미한다.

 이제, 그림 6에서 확인할 수 있는 $X^TX$의 의미는 무엇인가? 

그림 6의 마지막 수식을 보면 $X^TX$의 $i$행 $j$열의 성분인 $(X^TX)_{ij}$는 $d$개의 feature 중 $i$번째 feature와 $j$번째 feature가 얼마나 닮았는지를 모든 사람으로부터 값을 얻어서 내적 연산을 취함으로써 확인시켜준다. 

그런데 $X^TX$ 행렬이 가지는 문제는 숫자 $n$이 커질수록 내적 값은 계속 커진다는 것이다. 따라서 내적값들을 $n$으로 나누어주면 그 문제를 피할 수 있을 것이다. 그러면 다음과 같은 행렬을 생각할 수 있게 된다.

<p align="center">
<img width = "500" src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2019-07-27_PCA/XTX_n.png">
<br>
그림 X. 설명
</p>

그림 7에 표현되어 있는 행렬을 공분산 행렬이라고 부른다. 즉, 데이터 행렬 $X$에 대해서 공분산행렬 $\Sigma$는

$$
\Sigma = \frac{1}{n}X^TX
$$

이다[^sample_cov].


※ 여기부터는 고유벡터와 고유값, 라그랑주 승수법에 대해 공부하고 오는 것을 추천한다. ※

 그렇다면 이 때 공분산 행렬이 데이터의 어떤 측면을 설명해주는 것인가? 그림 8에서 확인할 수 있듯이 공분산 벡터 내의 원소들은 차원의 특징벡터 두 개의 내적으로 구성되어 있다. 내적은 벡터의 닮음의 척도이므로 공분산 행렬은 개의 차원 벡터들이 얼마나 닮았는지를 표현해주고 있는 것이다. 또, 그림 7에서 표현해주고 있듯이 내부의 공분산들은 변량들이 얼마나 함께 변하는지에 대해 말해주고 있다.

 공분산 행렬을 기하학적으로 파악해보도록 하자. 행렬이란 선형 변환이고 하나의 벡터 공간을 선형적으로 다른 벡터 공간으로 mapping 하는 기능을 가진다. 

 여기서 우리는 공분산 행렬에 의해 mapping 되는 mapping 전 단계의 벡터 공간을 다음과 같이 생각해보자. 

<center>

![](https://wikidocs.net/images/page/7646/10.png)

그림 8 2차원 벡터공간에 bivariate Gaussian distribution을 통해 random values를 원형으로 뿌려보았음</center>

그림 8의 벡터 공간에 공분산 행렬을 적용하여 선형 변환을 시켜주면 어떤 일이 일어나는지 알아보자. 그림 8에서 표현한 2차원 벡터공간에 대한 선형 변환은 그림 9과 같이 나타난다.


<center>

![](https://wikidocs.net/images/page/7646/11.png)

그림 9 공분산 행렬을 2차원 공간에 scatter된 bivariate Gaussian distribution으로부터 얻은 data point에 적용하면 위와 같이 선형 변환 된 결과를 얻을 수 있다. </center>

 고유벡터와 고유값의 의미를 잘 생각해보면, 고유 벡터는 그 행렬이 벡터에 작용하는 힘의 방향을 나타내므로 공분산 행렬의 고유 벡터는 데이터가 어떤 방향으로 분산되어 있는지를 나타내준다고 할 수 있다. 

고유 값은 고유벡터에 해당하는 상관 계수에 해당하므로, 우리가 다루는 행렬이 공분산 행렬일 경우 고유 값은 각 축에 대한 공분산 값이 된다. 따라서 고유 값이 큰 순서대로 고유 벡터를 정렬하면 결과적으로 중요한 순서대로 주성분을 구하는 것이 된다.



[^sample_cov]: 조금 더 엄밀하게는 n대신 n-1로 나누어주어야 sample의 covariance를 얻을 수 있다. n이 꽤 큰 숫자라면 크게 결과가 달라지지는 않겠지만...
