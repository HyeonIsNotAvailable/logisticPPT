---
title: GMM과 EM 알고리즘
sidebar:
  nav: docs-ko
aside:
  toc: true
key: 20210208
tags: 통계학 머신러닝
---

# Prerequisites

이 포스트를 더 잘 이해하기 위해선 아래의 내용에 대해 알고 오시는 것을 추천드립니다.

* [k-means 알고리즘](https://angeloyeo.github.io/2021/02/07/k_means.html)
* [최대우도법(Maximum Likelihood Estimation)](https://angeloyeo.github.io/2020/07/17/MLE.html)

# GMM (Gaussiam Mixture Model)

[//]:# (우리가 하고자 하는 일은 바로 모수 추정이라는 사실을 계속 말해줄 것)

[//]:# (라벨이 주어진 데이터들을 plot 해주고 그것들의 mean과 var는 비교적 쉽게 구할 수 있음 <- MLE 문제)

[//]:# (하지만 만약 우리가 label을 알 수 없다면? --> GMM 문제)

## [복습] 최대우도법을 이용한 정규분포 fitting

이전 [최대우도법](https://angeloyeo.github.io/2020/07/17/MLE.html) 시간에서는 어떤 데이터를 관찰하고 그 데이터에 맞는 모수를 추정하는 방법을 알아보았다.

특히, 예시로써 확인해 본 것은 주어진 데이터에 대한 정규분포의 fitting 이었다.

아래의 그림 1에서는 최대우도법을 이용하여 여러 평균값의 후보 중 적절한 것을 선택하는 예시를 보여주고 있다.

<p align = "center">
  <img width = "800" src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-07-17-MLE/pic1.png">
  <br>
  그림 1. 획득한 데이터와 추정되는 후보 분포 2개(각각 주황색, 파란색 곡선으로 표시)
</p>

좀 더 자세한 내용은 [최대우도법](https://angeloyeo.github.io/2020/07/17/MLE.html) 포스팅을 보는것이 좋겠으나 그림 1의 내용만을 간단히 얘기하자면, 수직선 상에 표시된 주황색 데이터들은 그림 1의 주황색 커브와 파란색 커브 중 주황색 커브로 부터 나왔을 가능성이 더 커보인다. 이것이 최대우도법의 핵심이었다.

그리고, 데이터에 대해 정규분포를 가정했을 때, 주어진 $m$개의 데이터에 대한 두 파라미터(평균, 분산)에 대한 최대우도법의 결론은 다음과 같았다.

우리에게 주어진 데이터를 $\lbrace x^{(1)}, x^{(2)}, \cdots, x^{(m)}\rbrace$이라 했을 때 평균, 분산 값을 계산할 때 likelihood 함수가 최대가 된다.

$$\hat{\mu}= \frac{1}{m}\sum_{i=1}^{m}x^{(i)}$$

$$\hat{\sigma}^2= \frac{1}{m}\sum_{i=1}^{m}(x^{(i)}-\mu)^2$$

위 결과는 우리가 익히 알고있는 평균, 분산에 관한 식이다. 하지만 이 결과는 주어진 데이터에 대한 우도(likelihood)를 계산한 뒤, 우도가 최대가 되게하는 평균과 분산 값을 얻은 결과라는 점을 기억해두도록 하자.


## 우리가 처한 문제와 해결 방법

아래의 그림 2에서와 같이 수직선 상에 데이터가 10개 주어져 있다고 생각해보자.

여기서 우리에게는 각 데이터에 label이 주어져있다고 해보자. (동그라미 안의 색깔이 서로 다른 label을 의미한다.)

<p align = "center">
  <img src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2021-02-08-GMM_and_EM/pic2.png">
  <br>
  그림 2. Label이 주어진 Density Estimation 문제 (MLE를 이용해 풀 수 있음)
</p>

그러면, 이 데이터 셋에 대한 확률 분포를 추정 할 수 있을까? 

여러가지 방법으로 확률 분포를 추정 할 수 있지만, 모수적인 방법으로 확률 분포를 추정 한다고 하면 우선 분포를 가정하고 거기에 맞는 모수들을 추정해야 한다. 앞서 언급한 방법인 최대우도법(MLE)은 주어진 데이터에 대해 분포의 모수를 추정할 수 있게 해주는 아주 좋은 방법이라고 할 수 있다. 아래의 그림 3은 그림 2에서 주어진 데이터들에 대해 정규분포를 가정하고 모수를 추정해 확률 분포를 추정한 결과라고 할 수 있다. 모수 추정 방법은 앞서 언급한 MLE의 결과를 이용하여 각 label에 해당하는 데이터들의 평균값과 표준편차 값을 계산함으로써 진행될 수 있다.

<p align = "center">
  <img src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2021-02-08-GMM_and_EM/pic3.png">
  <br>
  그림 3. label이 주어진 데이터와 이에 대해 추정한 두 분포
</p>

그런데, 만약 우리에게 label이 주어지지 않는다면 어떨까?

<p align = "center">
  <img src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2021-02-08-GMM_and_EM/pic4.png">
  <br>
  그림 4. label이 주어지지 않은 데이터들의 분포
</p>

위의 그림 4에서는 그림 2와 같은 데이터에 라벨이 주어지지 않은 경우를 보여주고 있다.

라벨을 부여하기 위해선 확률 분포가 필요한데, 확률 분포를 얻기 위해선 모수를 알아야 하고, 모수를 알기 위해선 다시 각 데이터에 라벨이 필요하다. 

다시 말해 우리에게 주어진 문제는 닭이 먼저냐 달걀이 먼자냐의 문제와 같다.

<center><b>☆★☆★라벨을 얻기 위해선 분포가 필요하고, 분포를 얻기 위해선 라벨이 필요하기 때문이다.☆★☆★</b></center>

따라서 우리가 할 수 있는 일은 랜덤하게 라벨을 주고 시작하던지, 랜덤하게 분포를 설정해주고 시작하던지 둘 중 하나이다.

우리는 각 라벨에 해당하는 분포를 랜덤하게 주어주고 시작해보도록 하자.

이 때, 분포는 각 라벨별 모수($\mu, \sigma$)를 선정하고 그에 따라 각 라벨에 대한 분포를 주어주고자 한다.

두 개의 분포가 주어졌다고 하면, 각 데이터에 대한 분포의 높이값(즉, likelihood)을 비교하여 라벨링을 해줄 수 있다.

주황색과 파란색을 각각 그룹 1, 그룹 2라고 했을 때, 각 그룹의 평균과 표준편차는 다음과 같았다고 해보자.

$$\mu_1 = 3, \sigma_1 = 2.9155$$

$$\mu_2 = 10, \sigma_2 = 3.9623$$

그럼 각 라벨에 대해 그림 5와 같은 분포를 확인할 수 있게 된다.

<p align = "center">
  <img src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2021-02-08-GMM_and_EM/pic5.png">
  <br>
  그림 5. 두 label(0, 1)에 대한 분포가 만약에 주어진다면?
</p>

위의 그림 5와 같은 분포가 random 하게 주어졌다고 하면 그 분포에 맞추어서 각각의 데이터들의 label을 선정할 수 있다. 아래의 그림 6에서는 $x=9$인 데이터 샘플의 label을 선정하고자 하는 과정을 보여주고 있다.

<p align = "center">
  <img src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2021-02-08-GMM_and_EM/pic6.png">
  <br>
  그림 6. 주어진 분포를 이용해 각각의 데이터 샘플들의 라벨을 선정할 수 있다. 이 경우 $x = 9$에 해당하는 데이터의 label은 1이 될 것이다.
</p>

그림 6의 방법을 이용하여 모든 데이터 샘플들에 대한 label을 확인하면 다음의 그림7과 같은 결과를 얻을 수 있을 것이다.

<p align = "center">
  <img src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2021-02-08-GMM_and_EM/pic7.png">
  <br>
  그림 7. 
</p>

자 그럼 이번에는 그림 7에서 확인한 label에 따라 각 그룹의 분포를 예측해보자.

각 그룹의 평균, 표준편차는 다음과 같다.

$$\mu_1 = 4, \sigma_1 = 2.1602$$

$$\mu_2 = 21.33, \sigma_2 = 7.0048$$

이 값을 이용해 각 그룹의 분포를 그려보면 다음과 같다.

<p align = "center">
  <img src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2021-02-08-GMM_and_EM/pic8.png">
  <br>
  그림 8. 
</p>

그림 5와 그림 8을 비교해보면 분명히 분포가 바뀐 것을 확인할 수 있을 것이다.

그러면 우리는 또 다시 이렇게 바뀐 분포를 이용해 라벨링을 새롭게 바꿀 수 있고, 이 과정을 계속 수행하다보면 결국 분포는 수렴할 것이라고 예상할 수 있다.

그 과정을 그림 한장으로 요약하면 대략적으로 다음과 같다.

<p align = "center">
  <img src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2021-02-08-GMM_and_EM/pic9.png">
  <br>
  그림 9. label이 주어져있지 않은 경우 clustering을 수행할 수 있는 방법
</p>

이러한 방법을 여러번 수행하게 되었을 때의 결과는 아래의 영상에서 확인할 수 있다.

아래 영상에서는 epoch = 10까지만 반복을 수행하였지만, 분포가 수렴하지 않아 추가 반복이 필요한 경우 얼마든지 iteration 수는 늘릴 수 있다.

<p align = "center">
  <video width = "600" height = "auto" loop autoplay controls muted>
    <source src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2021-02-08-GMM_and_EM/pic9.mp4">
  </video>
  <br>
  그림 10. label이 없이 주어진 데이터에 대한 clustering 수행 과정
</p>


## EM 알고리즘을 이용한 GMM 모델링

이전 꼭지에서 우리가 처한 문제와 해결 방법에 대해서 생각해보았다.

다시 정리하자면, 우리가 처한 문제는 라벨이 없는 데이터들이 주어졌다는 점이었으며, 우리가 필요한 해답은 각 라벨 별 분포였다.

이 문제가 어려운 이유는 라벨을 얻기 위해선 분포가 필요하고, 분포를 얻기 위해선 라벨이 필요하기 때문이었는데, 문제의 해결을 위해

랜덤하게 분포를 주어준 뒤 라벨을 얻고, 그 라벨들을 이용해 다시 분포를 얻는 방식으로 clustering을 수행하였다.

이것은 일반적으로 EM-알고리즘이라고 하는 것을 조금 쉽게 풀어 쓴 것이다.


EM 알고리즘은 Expectation-Maximization의 약자인데,

여기서 Expectation은 로그 가능도의 기댓값을 계산하는 과정이다 라고 하는데, 그냥 라벨을 찾는 과정이라고 보면 좋을 것 같고

Maximization은 Maximum Likelihood Estimation을 수행해서 모수를 추정하는 과정이라고 볼 수 있다.

즉, E-step에서는 "변수의 정보(즉, 이 변수의 라벨은?)"를 업데이트 하고, M-step에서는 "변수들이 어떻게 분포 되어 있는지에 대한 가설"을 업데이트하는 과정이라고 봐도 좋을 것 같다.

Repeat until convergence: {

  $\quad$(E-step) For each $i$, $j$, set

  $$w_j^{(i)} := p(z^{(i)} = j|x^{(i)};\phi,\mu,\Sigma) $$

  $\quad$(M-step) Update the parameters:

  $$\phi_j := \frac{1}{m}\sum_{i=1}^{m}w_j^{(i)}$$

  $$\mu_j := \frac{\sum_{i=1}^{m}w_j^{(i)}x^{(i)}}{\sum_{i=1}^{m}w_j^{(i)}}$$

  $$\Sigma_j := \frac{\sum_{i=1}^{m}w_j^{(i)}\left(x^{(i)}-\mu_j\right)\left(x^{(i)}-\mu_j\right)^T}{\sum_{i=1}^{m}w_j^{(i)}}$$
  
}

베이즈 정리에 따르면,

$$p(z^{(i)}=j|x^{(i)};\phi,\mu,\Sigma) =\frac{p(x^{(i)}|z^{(i)} = j; \mu, \Sigma)p(z^{(i)}=j;\phi)}{p(x^{(i)};\phi, \mu, \Sigma)} $$

$$= \frac{p(x^{(i)}|z^{(i)} = j; \mu, \Sigma)p(z^{(i)}=j;\phi)}{\sum_{k=1}^{l}p(x^{(i)}|z^{(i)} = l; \mu, \Sigma)p(z^{(i)}=l;\phi)}$$

##

<p align = "center">
  <video width = "700" height = "auto" loop autoplay controls muted>
    <source src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2021-02-08-GMM_and_EM/pic1.mp4">
  </video>
  <br>
  그림 1. 
</p>
