---
title: 반복측정 분산분석(Repeated Measures ANOVA)
sidebar:
  nav: docs-ko
aside:
  toc: true
key: 20211102
tags: 통계학
---

이 포스팅은 Primer of Biostatistics, S. Glantz, 7판을 참고하여 작성하였습니다.

※ 이 포스팅은 계산이 복잡한 편입니다. RM ANOVA에 대해 계산 과정을 바닥까지 이해해보고자 하시는 분들에게만 추천드립니다. 다만 사칙연산 이상의 산수 수준을 요구하지는 않습니다. ※

# Prerequisites

이 포스팅의 내용을 잘 이해하기 위해선 아래의 내용에 대해 알고 오시는 것을 추천합니다.

* [표본과 표준 오차의 의미](https://angeloyeo.github.io/2020/02/12/standard_error.html)
* [F-value의 의미와 분산분석](https://angeloyeo.github.io/2020/02/29/ANOVA.html)
* [대응 표본 t-검정](https://angeloyeo.github.io/2021/10/29/paired_t_test.html)

# Motivation

대응 표본 t-검정에서는 피험자들의 before / after 차이를 확인할 수 있었다. 그런데, 어떤 경우에는 애프터 이후의... 삼프터, 사프터(??)도 한번에 비교하고 싶을 때도 있지 않을까?

좋은 예시 중 하나로 의학적 처치 후의 팔로우-업(follow-up)이 있다.

팔로우-업은 처치의 before / after를 확인 후 일정 기간이 지난 뒤에 한번 더(가령 1년 후) 검진을 수행해 경과를 관찰하는 것을 말한다.

즉, 팔로우 업을 한번만 수행한다면 동일 피험자에 대해 세 번의 시간에 걸쳐 측정이 진행되는 것과 마찬가지다[^1].

[^1]: 추후에 더 서술하겠지만 반복 측정이 꼭 시간에 한정되는 개념은 아니다. 시간적이거나 공간적인 차원에서 모두 반복 측정이 가능하다.

이것을 분석하기 위한 통계적 기법이 바로 반복측정 분산분석(Repeated Measures ANOVA)이며 줄여서 RM ANOVA라고도 많이 부른다.

이번 포스팅에서는 One-Way ANOVA에 대해서 좀 더 자세하게 알아본 뒤 반복측정 분산분석을 설명할 것이다.

One-way ANOVA는 [F-value의 의미와 분산분석](https://angeloyeo.github.io/2020/02/29/ANOVA.html) 편에서 보았던 분산분석을 좀 더 구체적으로 일컫는 말인데, 

[F-value의 의미와 분산분석](https://angeloyeo.github.io/2020/02/29/ANOVA.html) 편에서 본 방식과는 다르게 변동(혹은 제곱합)이라는 관점에서 ANOVA를 설명하고자 한다.

변동이라는 개념을 도입해 ANOVA를 이해하게 되면 수식이 많아지고 내용이 복잡해지는데, 그럼에도 불구하고 조건이 다양해지면 직관만으로는 문제를 풀어나가기 어렵기 때문에 수식의 도움을 받아야 할 수 밖에 없다.

# One-way ANOVA와 제곱합(Sum of Squares)

분산분석을 공부할 때 있어서 제곱합이라는 개념이 가장 큰 걸림돌이 된다. 처음 들으면 다소 생소한 개념일 수 있으나 제곱합의 개념은 분산 분석에서 아주 중요한 개념이다. 일단은 제곱합을 왜 사용해야 할까?

보통 분산 분석에서 제곱합이라고 하는 것은 좀 더 정확히 쓰자면 편차 제곱합(sum of squares of difference)라고 쓰는 것이다. 이 이름을 보면 우리가 생각해봐야 하는 것은 두 가지이다. 왜 편차에 관심을 가져야 하고 제곱합에 관심을 가져야 할까?

우선, 편차에 대해 생각해보자. 어떤 비교든지 간에 비교의 시작은 빼기(-)를 수행해줘야 비교할 수 있다. 그렇게 어려울 것이 없다. 비교를 위해서 편차를 생각하는 것은 자연스러운 논리적 흐름이라고 할 수 있다.

그럼 제곱은 왜 해줄까? 우선은 부호를 제거해주기 위한 목적이 있다. 편차는 양수, 음수 모두 나올 수 있기 때문에 합해주는 과정에서 복잡함이 생긴다. 절대값을 씌워줄 수도 있지만 그것보다는 제곱을 취하는 편이 계산에 편리하다. 따라서, 부호에 관계 없이 '변동'의 의미만을 남기고자 하는 것이다. 

그런데, 제곱합을 이용하는 것이 끝까지 살아남은 이유는 전체 제곱합은 특별한 의미를 지닌 제곱합들로 쪼개 생각할 수 있기 때문이다. 무슨 말인지 감이 오지 않을텐데, 뒤에서 더 설명할 "ANOVA를 SS 관점에서 이해해보기"를 들여다보면 더 깊게 이해할 수 있을 것이다. 

이 시점부터는 제곱합을 SS(Sum of Squares)라고 줄여 적도록 하겠다.

## 용어 정리

SS를 이용해 ANOVA를 이해해보기에 앞서 용어를 미리 정리하고 넘어가도록 하자.

처음보는 용어들이기 때문에 계속해서 이 부분을 참고해가면서 이해한다면 도움이 될 것이라 믿는다. 각 용어에 대한 자세한 설명은 아래의 유도 과정을 따라가면서 붙여나갈 것이다.

- $SS_\text{something}$이라고 쓰면 something에 의해서 설명되는 제곱합이다. 

- 자유도(degree of freedom; DF)는 주어진 조건 안에서 통계적인 추정을 할 때에 표본이 되는 자료 중에 모집단에 대한 정보를 주는 독립적인 자료의 수를 말한다.

   $DF_\text{something}$이라고 쓰면 something이라는 조건에 관한 자유도를 말한다.

- 평균 제곱(mean square; MS)은 SS의 평균으로써, 산술적 평균이 아니라 SS를 자유도로 나눈 값이다. 

   즉, 평균적인 편차라는 의미에서 일종의 분산 역할을 한다. 다만 분산과 개념을 구분시켜 생각하는 이유는 MS는 여러가지 이유로 자유도가 수정되면 수정될 수 있는 통계치이기 때문이다.

## ANOVA를 SS의 관점에서 이해해보기

우리는 [F-value의 의미와 분산분석](https://angeloyeo.github.io/2020/02/29/ANOVA.html) 편에서 분산분석을 수행하는 과정을 확인해보았다.

분산분석은 기본적으로 모든 샘플 집단이 하나의 모집단에서 나왔다는 귀무가설을 가지고 진행된다.

그리고 ANOVA에서는 이 귀무가설을 확인하기 위해 두 가지 방법으로 분산을 추정한다. 첫 번째는 각 샘플 집단들이 가지고 있는 분산값을 이용하는 것이고 두 번째는 각 샘플 그룹의 평균값들이 퍼진 정도를 이용해서 분산을 추정하는 것이다. 만약 집단 내의 분산에 비해 샘플 집단 평균 간의 분산이 너무 크다면 우리는 귀무가설이 맞기 어려울 것이라고 보고 귀무가설을 기각해 적어도 하나의 샘플 집단은 다른 모집단에서 추출되었을 것이라고 볼 수 있다고 했다.

이 때, 분산의 비율값을 F 값이라고 불렀다. 즉, F 값을 수식으로 쓰면,

$$F=\frac{s^2_\text{bet}}{s^2_\text{wit}}$$

이다. 여기서 

$$s^2_\text{bet}$$

는 그룹 간 분산의 추정값, 

$$s^2_\text{wit}$$

는 그룹 내 분산의 추정값을 말한다.

F 값의 확률 분포는 잘 알려져 있기 때문에 주어진 샘플 그룹으로부터 계산한 F 값이 얼마나 상대적으로 큰 값인지 계산할 수 있는 것이고 이를 통해 통계적 유의성을 검증한다.

(만약 위 내용이 잘 이해되지 않는다면 [F-value의 의미와 분산분석](https://angeloyeo.github.io/2020/02/29/ANOVA.html) 편을 보시는 것을 추천드립니다.)

---

[F-value의 의미와 분산분석](https://angeloyeo.github.io/2020/02/29/ANOVA.html) 수행해보았던 계산을 다시 한번 수행해보자.

다만, SS를 이용해서 ANOVA의 계산식을 새롭게 써보려고 하기 때문에 이전 ANOVA 포스팅의 내용에 비해 계산 과정은 훨씬 더 복잡할 것이다. 같은 결과를 얻기 위해 이런 복잡한 과정을 거치는 일이 꼭 필요한가 싶겠지만, 좀 더 복잡한 조건을 갖는 ANOVA를 수행하기 위해선 이런 과정은 불가피하다고 할 수 있다.

주어진 데이터 셋은 아래와 같이 표로 정리된 값으로 생각해보도록 하자.

<p align = "center">
  <img width = "600" src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2021-11-02-RM_ANOVA/pic1.png">
  <br>
  그림 1. 분산분석에 사용되는 데이터를 표와 기호로 정리한 것
</p>

그룹 내 분산($s^2_\text{wit}$)은 각 treatment 그룹 별 분산을 평균낸 것으로 볼 수 있다고 하였으므로[^2] 다음과 같이 계산할 수 있는 값이다. 각 treatment 그룹의 분산을 $s_1^2, s_2^2, s_3^2$ 등이라고 한다면 아래와 같이 계산될 수 있다.

[^2]: 좀 더 정확히는 pooling 처리한 pooled variance이다.

$$s^2_\text{wit}=\frac{1}{3}\left(s_1^2 + s_2^2 + s_3^2\right)$$

$$=\frac{1}{3}\left(
  \frac{\sum_s\left(X_{1s}-\bar{X}_1\right)^2}{n-1} 
  + \frac{\sum_s\left(X_{2s}-\bar{X}_2\right)^2}{n-1}
  + \frac{\sum_s\left(X_{3s}-\bar{X}_3\right)^2}{n-1}
  \right)$$

여기서

$$SS_1 = \sum_s\left(X_{1s}-\bar{X}_1\right)^2$$

$$SS_2 = \sum_s\left(X_{2s}-\bar{X}_2\right)^2$$

$$SS_3 = \sum_s\left(X_{3s}-\bar{X}_3\right)^2$$

와 같이 써주면, (여기서 아랫첨자 $s$는 subject, $t$는 treatment를 의미할 것이다.)

그룹 내 분산 값은

$$s^2_\text{wit}=\frac{1}{3}\left(
  \frac{SS_1}{n-1} + \frac{SS_2}{n-1} + \frac{SS_3}{n-1}
  \right)$$

과 같고, 조금 더 요약해보면,

$$s^2_\text{wit}=\frac{1}{3}\left(
  \frac{SS_1+SS_2+SS_3}{n-1}
  \right)=\frac{\sum_t SS_t}{3(n-1)}=\frac{\sum_t \sum_s\left(X_{ts}-\bar{X}_t\right)^2}{3(n-1)}$$

과 같다. 여기서 $SS_1+SS_2+SS_3$이 각 treatment 그룹 내에서 평균으로부터 각 샘플값이 떨어진 정도의 제곱합을 의미하므로 $SS_\text{wit}$라고 쓰자. 그리고 
각 그룹별 표본의 개수는 $n$개, 그룹의 수는 $m$개라고 한다면,

$$s^2_\text{wit}=\frac{SS_{wit}}{m(n-1)}=\frac{SS_\text{wit}}{DF_\text{wit}}$$

과 같다. 그러므로 그룹 내 분산 값은 $SS_\text{wit}$을 자유도 $DF_\text{wit}=m(n-1)$로 나눈 값과 같다는 것을 알 수 있다.

그렇다면 이번에는 그룹 간 분산을 생각해보자. 우리는 각 그룹의 평균값을 알고 있기 때문에 각 그룹의 평균값이 갖는 [표준 오차](https://angeloyeo.github.io/2020/02/12/standard_error.html)를 생각해볼 수 있다. 

$$s^2_{\bar{X}}=\frac{s^2_\text{bet}}{n}$$

여기서 $S_{\bar{X}}$는 각 treatment 평균이 퍼진 정도, 즉 표준 오차를 얘기한다.

그러므로,

$$s^2_{\bar{X}} = \frac{(\bar{X}_1-\bar{X})^2+(\bar{X}_2-\bar{X})^2+(\bar{X}_3-\bar{X})^2}{m-1}$$

$$=\frac{\sum_t(\bar{X}_t-\bar{X})^2}{m-1}$$

임을 알 수 있다. 한편 식 (12)를 살짝만 틀어서 생각해주면

$$s^2_\text{bet}=ns^2_{\bar{X}}$$

이므로,

$$s^2_{\text{bet}}=\frac{n\sum_t(\bar{X}_t-\bar{X})^2}{m-1}$$

과 같이 $s^2_{\text{bet}}$을 계산할 수 있다는 점을 알 수 있으며, 더군다나 분자의

$$n\sum_t(\bar{X}_t-\bar{X})^2$$

이라는 식이 가져다주는 의미가 grand mean $\bar{X}$로부터 각 treatment의 평균값이 떨어진 정도라는 것을 알 수 있다. 그리고 m개의 그룹으로부터 분산을 계산할 때의 자유도는 m-1이다는 사실 또한 생각할 수 있다. 그러므로,

$$s^2_{\text{bet}}=\frac{n\sum_t(\bar{X}_t-\bar{X})^2}{m-1}=\frac{SS_\text{bet}}{DF_\text{bet}}$$

과 같이 $s^2_{\text{bet}}$을 SS를 이용해 써볼 수 있다는 점 또한 알 수 있다.

자, 지금까지 알아본 SS를 정리해보면 다음과 같이 정리할 수 있다.

$$SS_\text{wit}=\sum_t\sum_s\left(X_{ts}-\bar{X}_t\right)^2$$

$$SS_\text{bet}=n\sum_t\left(\bar{X}_t-\bar{X}\right)^2$$

그리고 마지막으로 우리는 각 샘플들이 grand mean $\bar{X}$로부터의 편차 제곱합인 

$$SS_\text{tot}=\sum_t\sum_s\left(X_{ts}-\bar{X}\right)^2$$

을 생각할 수도 있다.

앞서 제곱합(Sum of squares, SS)에 대해 설명할 때 제곱합을 이용하는 방법이 끝까지 살아남은 이유는 전체 제곱합은 특별한 의미를 지닌 제곱합들로 쪼개 생각할 수 있기 때문이라고 했다. 아래 꼭지에서 증명할 수 있듯이 $SS_\text{tot}$은 $SS_\text{bet}$와 $SS_\text{wit}$로 나눠 쓸 수 있다.

$$SS_{\text{tot}}=SS_{\text{bet}} + SS_{\text{wit}}$$

그 뿐인가? 자유도(degree of freedom)도 마찬가지 구조로 쪼개 생각할 수 있다.

$$DF_{\text{tot}}=DF_{\text{bet}} + DF_{\text{wit}}$$

<p align = "center">
  <img src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2021-11-02-RM_ANOVA/pic2.png">
  <br>
  그림 2. one-way ANOVA에서 제곱합, 자유도의 분해(partitioning)
  <br>
  출처: Primer of biostatistics, Stanton A. Grantz
</p>

이 쯤 되면 ANOVA를 공부하는데 왜 SS가 필요한지 슬슬 궁금해질 것이다. 이것은 RM ANOVA를 배울 때에야 비로소 이해할 수 있기 때문에 조금만 더 인내심을 요구한다. 우선은 total 제곱합이 그룹 내 제곱합과 그룹 간 제곱합으로 분해될 수 있다는 점을 수식적으로 확인해보고 예제 문제를 풀어보도록 하자. 

## (skip 가능) ANOVA Sum of Squares의 분할 (증명)

※ $SS_\text{tot}=SS_\text{bet} + SS_\text{wit}$의 증명과정은 필수적인 것은 아닙니다. 너무 복잡하다고 생각되시면 skip하세요.

$SS_\text{tot}=SS_\text{bet} + SS_\text{wit}$임을 확인하기 위해 $SS_\text{tot}$의 괄호 안에 있는 식을 아래와 같이 분할해 생각해보자.

$$(X_{ts}-\bar{X}) = (\bar{X}_t - \bar{X}) + (X_{ts}-\bar{X}_t)$$

여기서 양변을 제곱하면,

$$(X_{ts}-\bar{X})^2 = (\bar{X}_t - \bar{X})^2 + (X_{ts}-\bar{X}_t)^2 + 2(\bar{X}_t-\bar{X})(X_{ts}-\bar{X}_t)$$

과 같다.

여기서 모든 샘플에 대한 합을 구하면 total SS를 구하는 것과 같다는 점을 알 수 있다.

$$SS_\text{tot} = \sum_t\sum_s(X_{ts}-\bar{X})^2$$

$$=\sum_t\sum_s(\bar{X}_t - \bar{X})^2 + \sum_t\sum_s(X_{ts}-\bar{X}_t)^2 + \sum_t\sum_s2(\bar{X}_t-\bar{X})(X_{ts}-\bar{X}_t)$$

위 식에서 첫 번째 항의 괄호 내부 식은 $s$와 관계없는 식이므로,

$$\sum_t\sum_s(\bar{X}_t-\bar{X})^2=n\sum_t(\bar{X}_t-\bar{X})^2$$

이며 이것은 $SS_\text{bet}$와 같다.

한편, 세 번째 항은 다음과 같이 쓸 수 있는데,

$$\sum_t\sum_s2(\bar{X}_t-\bar{X})(X_{ts}-\bar{X}_t)

=2\sum_t\left(
  (\bar{X}_t-\bar{X})\sum_s(X_{ts}-\bar{X}_t)
  \right)$$

여기서 가장 내부의 $\sum_s$에 관한 식을 보면,

$$\sum_s(X_{ts}-\bar{X}_t)=\sum_sX_{ts}-\sum_s\bar{X}_t$$

$$=\sum_sX_{ts}-n\bar{X}_t$$

과 같이 풀어 쓸 수 있는데, $\bar{X}_t$는 정의상 

$$\bar{X}_t=\frac{1}{n}\sum_sX_{ts}$$

이므로,

$$\Rightarrow \sum_s(X_{ts}-\bar{X}_t)=\sum_sX_{ts}-n\frac{1}{n}\sum_sX_{ts} = 0$$

이다.

그러므로

$$SS_\text{tot} = \sum_t\sum_s(X_{ts}-\bar{X})^2$$

$$=\sum_t\sum_s(\bar{X}_t - \bar{X})^2 + \sum_t\sum_s(X_{ts}-\bar{X}_t)^2 + \sum_t\sum_s2(\bar{X}_t-\bar{X})(X_{ts}-\bar{X}_t)$$

$$=n\sum_t(\bar{X}_t - \bar{X})^2 + \sum_t\sum_s(X_{ts}-\bar{X}_t)^2 + 0$$

$$=SS_\text{bet}+SS_\text{wit}$$

이다.

## One-Way ANOVA 예시 문제

아래와 같은 데이터가 주어져 있다고 생각해보자.

이 때, 네 그룹 중 한 그룹이라도 다른 모집단에서 추출되었을 가능성이 있는지 타진해보도록 하자.

각 그룹의 샘플들은 모두 독립적으로 추출되었다고 생각하면 One-Way ANOVA를 이용해볼 수 있다.

| 그룹 1 | 그룹 2 | 그룹 3 | 그룹 4 |
| :---: | :---: | :---: | :---: |
| 4.6 | 4.6 | 4.3 | 4.3 |
| 4.7 | 5.0 | 4.4 | 4.4 |
| 4.7 | 5.2 | 4.9 | 4.5 |
| 4.9 | 5.2 | 4.9 | 4.9 |
| 5.1 | 5.5 | 5.1 | 4.9 |
| 5.3 | 5.5 | 5.3 | 5.0 |
| 5.4 | 5.6 | 5.6 | 5.6 |

앞서 공부한 방식을 그대로 이용하기 위해 그룹 내 분산과 그룹 간 분산을 Sum of Squares를 이용해 계산하자.

먼저 그룹 내 분산 $s^2_\text{wit}$을 계산해보자.

각 그룹별로 평균을 내고, 평균에서 얼마만큼 떨어져있는지를 계산하자.

각 그룹별로 평균은

$$\bar{X}_1 = 4.9571, \bar{X}_2 = 5.2286, \bar{X}_3 = 4.9286, \bar{X}_4 = 4.8000$$

과 같다.

그러므로 각 그룹 별 그룹 내 sum of squares인 $SS_1, SS_2, SS_3, SS_4$를 구하면,

$$SS_1 = (4.6-\bar{X}_1)^2 + (4.7 - \bar{X}_1) ^2 + (4.7 - \bar{X}_1) ^2 + \cdots + (5.4-\bar{X}_1)^2 = 0.5971$$

$$SS_2 = (4.6-\bar{X}_2)^2 + (5.0 - \bar{X}_2) ^2 + (5.2 - \bar{X}_2) ^2 + \cdots + (5.6-\bar{X}_2)^2 = 0.7343$$

$$SS_3 = (4.3-\bar{X}_3)^2 + (4.4 - \bar{X}_3) ^2 + (4.9 - \bar{X}_3) ^2 + \cdots + (5.6-\bar{X}_3)^2 = 1.2943$$

$$SS_4 = (4.3-\bar{X}_4)^2 + (4.4 - \bar{X}_4) ^2 + (4.5 - \bar{X}_4) ^2 + \cdots + (5.6-\bar{X}_4)^2 = 1.2000$$

이므로 $SS_\text{wit}$는

$$SS_\text{wit}=\sum_t SS_t = 0.5971+0.7343+1.2943+1.2000 = 3.8257$$

이고 $DF_\text{wit}$는 

$$DF_\text{wit} = m(n-1) = 4\times(7-1) = 24$$

이므로 $MS_\text{wit}$는

$$MS_\text{wit} = \frac{SS_\text{wit}}{DF_\text{wit}}=\frac{3.8257}{24}=0.1594$$

이다.

이번에는 그룹 간 분산 $s^2_\text{bet}$을 계산해보자.

각 그룹 별 평균은 앞서 확인했기 때문에 이 그룹 별 평균들이 전체 평균(grand mean)으로부터 얼마나 떨어져있는지를 파악함으로써 그룹 간 분산을 구할 수 있다.

전체 평균은

$$\bar{X}= 4.9786$$

이므로,

$$SS_\text{bet}=n \sum_{t}(\bar{X}_t-\bar{X})^2 $$

$$= 7\times \left((4.9571-4.9786)^2+(5.2286-4.9786)^2 +(4.9286-4.9786)^2 + (4.8000-4.9786)^2\right)\notag$$

$$=0.6814$$

이고, 

$$DF_\text{bet}=m-1 = 3$$

이므로,

$$MS_\text{bet}=\frac{SS_\text{bet}}{DF_\text{bet}}=0.2271$$

임을 알 수 있다.

따라서, 우리가 구하고자 하는 F 값은

$$F = \frac{MS_\text{bet}}{MS_\text{wit}}=\frac{0.2271}{0.1594}=1.4249$$

임을 알 수 있으며, 분자, 분모의 자유도는 각각 3, 24이므로 이 때 대응되는 우리의 $F$값의 p-value는 0.26에 불과하다.

One-way ANOVA의 결과를 정리하면 다음과 같다.

| Source | SS | df | MS | F | Prob > F |
| :---: | :---: | :---: | :---: | :---: | :---: |  
| Between | 0.68143 | 3 | 0.22714 | 1.42 | 0.26    |
| Within | 3.82571 | 24 | 0.1594 |     |     |
| Total | 4.50714 | 27 |  |     |     |

# Repeated Measures ANOVA

Motivation 파트에서 설명했듯이 Repeated Measures ANOVA(이후 RM ANOVA)는 피험자 한 명이 여러 번의 treatment를 받은 경우에 적용할 수 있는 분석 기법이다.

One-Way ANOVA에서는 전체 변동(variation) 혹은 제곱합(Sum of Squares 이하 SS)이 그룹 간 변동($SS_\text{bet}$)과 그룹 내 변동($SS_\text{wit}$)으로 나눠졌다고 하면

RM ANOVA에서는 전체 변동이 피험자 간의 변동, treatment에 의해 생기는 변동, treatment에 반응하는 피험자 내의 변동의 세 가지 변동으로 나누어진다.

<p align = "center">
  <img width = "600" src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2021-11-02-RM_ANOVA/pic3.png">
  <br>
  그림 3. (좌) 분산분석에서 변동의 분할 (우) 반복측정 분산 분석에서 변동의 분할(partitioning)
  <br>
  출처: Primer of biostatistics, Stanton A. Grantz
</p>

선뜻 보기에는 변동이 더 복잡하게 많이 나눠지니까 이해하기 어려울 수도 있겠다 생각이 들지만, 집중해야 할 것은 서로 다른 SS들이 상호 배타적으로(mutually exclusive) 구성된다는 점이다.

그리고 가장 중요하게 다루어야 하는 문제는 우리가 어떤 변동에 관심이 있는지를 정확히 캐치하는 것이다.

만약 100명의 헬스장 회원들이 3회에 걸쳐 체지방을 측정한다고 했을 때, 우리는 어떤 변동에 집중해야 할까?

회원들 간의 변동량(between subjects variation), 회차에 따른 체지방 측정량의 변화(between treatments variation), treatment에 반응하는 회원들 내부 변동(residual variation) 세 가지를 놓고 생각해보자.

여기서 우리는 회차에 따른 체지방 측정량의 변화에 대해 관심이 있다. 

그리고 이것을 통계적으로 처리하기 위해 마치 [t-test](https://angeloyeo.github.io/2021/10/29/paired_t_test.html)를 공부할 때 그룹 간 차이를 불확실성으로 나누어주었듯이

시간에 따른 체지방 측정량의 변동값을 회원들 내부 변동으로 나누어준 값을 가지고 어떤 결과를 내는 것이 우리의 관심사가 될 수 있다는 것을 알 수 있다.

treatment에 반응하는 회원들 내부 변동이라는 말이 우리가 측정할 수 없는 error에 대한 변동이라는 말을 내포하고 있기 때문이다.

따라서 우리는 F-value를 계산할 때 시간에 따른 체지방 측정량의 변동값과 회원들이 내재하고 있는 변동량을 나누어 계산해준 뒤 유의성을 판단하면 되는 것이다.

## RM ANOVA의 계산 수행 과정

앞서 간략하게 소개한 RM ANOVA의 분석 과정을 구체적으로 계산해보면서 진행해보자.

우선은 RM ANOVA를 이용해 분석할 수 있는 반복측정 데이터의 구조를 살펴보자.

<p align = "center">
  <img width = "600" src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2021-11-02-RM_ANOVA/pic4.png">
  <br>
  그림 4. 반복측정 데이터를 표와 기호로 정리한 것
</p>

그림 4에서는 반복측정 데이터를 표와 기호로 정리했다. 선뜻 보기에는 그림 1의 데이터와 다를게 없어보이지만 가장 핵심적인 차이는 그림 4에서 주어진 데이터들은 각 treatment 그룹에 있는 subject들이 같은 subject들이라는 것이다. 가령 그림 1에서는 데이터의 첫 번째 행에 있는 값들($X_{11}, X_{21}, X_{31}$)은 서로 다른 1번 피험자들이 수행하여 얻은 값이지만, 그림 4에서는 데이터 첫 번째 행에 있는 값들($X_{11}, X_{21}, X_{31}$)은 모두 동일한 피험자가 세 차례에 걸쳐 획득한 데이터가 되는 것이다.

## Sum of Squares 의 분할(증명)

$$SS_{tot} = \sum_{t}\sum_{s}(X_{ts}-\bar{X})^2$$

Let 

$$a_{ts} = X_{ts} - \bar{S_s}$$

where 

$$\bar{S_s} = \frac{1}{m}\sum_{t}X_{ts}$$

and

$$b_s = \bar{S_s}-\bar{X}$$

then,

$$X_{ts}-\bar{X} = X_{ts}-\bar{S_s} + \bar{S_s} - \bar{X}$$

$$=a_{ts}+b_s$$

We can figure out that...

$$\sum_{t}a_{ts}=\sum_t\left(X_{ts}-\bar{S_s}\right)$$

$$=\left(\sum_{t}X_{ts}\right)-m\bar{S_s}$$

$$=\sum_{t}X_{ts}-m\cdot\frac{1}{m}\sum_{t}X_{ts} = 0$$

Hence,

$$SS_{tot}=\sum_{t}\sum_{s}(X_{ts}-\bar{X})^2$$

$$=\sum_{t}\sum_{s}\left(a_{ts}+b_s\right)^2$$

$$=\sum_{t}\sum_{s}\left(a_{ts}^2+b_s^2+2a_{ts}b_s\right)$$

$$=\sum_{t}\sum_{s}\left(a_{ts}^2\right)+\sum_{t}\sum_{s}\left(b_s^2\right)+2\sum_{s}\left(b_s\left(\sum_{t}a_{ts}\right)\right)$$

식 ()~()에서 본 것 처럼 $\sum_t a_{ts}=0$과 같다. 따라서,

$$\Rightarrow \sum_{t}\sum_{s}\left(a_{ts}^2\right)+\sum_{t}\sum_{s}\left(b_s^2\right)+2\sum_{s}\left(b_s\left(0\right)\right)$$

$$=\sum_{t}\sum_{s}\left(a_{ts}^2\right)+\sum_{t}\sum_{s}\left(b_s^2\right)$$

$a_{ts}$와 $b_{s}$의 정의를 이용해 식을 다시 써주면,

$$\Rightarrow \sum_{t}\sum_{s}\left(X_{ts}-\bar{S}_s\right)^2+\sum_{t}\sum_{s}\left(\bar{S}_s-\bar{X}\right)^2$$

와 같다. 이 식에서 좌측에 있는 값이 $SS_{wit\cdot subj}$이고 우측에 있는 값이 $SS_{bet\cdot subj}$가 된다.

## 구형성

### Mauchly's test

### Epsilon 보정

Greenhouse-Geisser

Huyhn-Feldt

## RM ANOVA 예시 문제

MATLAB은 RM ANOVA 사용이 어렵다.

SAS, SPSS는 너무 비싸다.

R을 배울 시간은 또 없다면, Jamovi를 다운받아보자.

## Jamovi

# 참고문헌

* Primer of biostatistics, 7th ed., S. Glantz / Ch. 9 Experiments when each subject receives more than one treatment
* Statistical principles in experimental Design, 1st ed., B. J. Winer / Ch. 4 Single-factor experiments having repeated measures on the same elements