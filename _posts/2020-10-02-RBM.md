---
title: Restricted Boltzmann Machine
sidebar:
  nav: docs-ko
aside:
  toc: true
key: 20201002
tags: 기계학습
---

# 확률분포를 알 수만 있다면...

Restricted Boltzmann Machine(이하 RBM)은 Generative Model이라고 하는데, ANN, DNN, CNN, RNN 등과 같은 Deterministic Model들과 약간 다른 목표를 갖고 있다.

Deterministic Model들이 타겟과 가설 간의 차이를 줄여서 오차를 줄이는 것이 목표라고 한다면, Generative Model들의 목표는 확률밀도함수를 모델링하는 것이다.

확률 밀도 함수(probability density function, pdf)를 정확히 안다는 것은 무엇일까?

가령 얼굴을 그려주는 기계가 있다고 하자. 얼굴은 여러가지 요소로 구성되어 있는데, 가령 코를 그려준다고 해보자.

코 역시도 여러가지 다양한 가능한 경우의 형태로 구성되어 있다. 여기서 만약, 세상에 코의 형태가 동그라미, 세모, 네모 코만 있다고 가정했을 때, 

우리가 이 세가지 형태의 코에 대한 확률밀도함수를 알 수 있다고 하자. 즉, 온 세상의 얼굴에서 코의 형태를 다 조사해 histogram을 그려보았다고 해보자.

<p align = "center">
  <img src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-10-02-RBM/pic1.png">
  <br>
  그림 1. 코의 모양에 대한 확률 분포
</p>

위의 그림을 보면 세모(▲) 모양의 코가 전 세상에서 가장 흔하다는 것을 알 수 있다.

아마 얼굴 그려주는 기계가 이런 확률 분포에 대해 알고 있다면 얼굴을 그릴 때 코에 대해서는 세모 모양의 코를 그려줄 가능성이 좀 더 높아 보인다.

이런 식으로 모든 가능한 경우에 대해 어떤 사건이 발생할 확률을 정확히 알 수 있다면, 여러 사건들의 조합으로 구성되는 사건(즉, 여기서는 전체 얼굴)을 일리있게 **생성**할 수 있게 되는 것이다.

실제로 Generative Model 중 요즘 유행하는 GAN(Generative Adversarial Networks)을 이용해 생성된 얼굴은 다음 그림에서 볼 수 있다.

<p align = "center">
  <img src = "https://www.researchgate.net/publication/341699736/figure/fig2/AS:896007655149568@1590636280012/45-years-of-GAN-progress-on-face-generation-20147-201510-201611-201712.png">
  <br>
  그림 2. GAN을 이용해 만들어진 얼굴 변천사
  <br>
  <a href = "https://www.researchgate.net/publication/341699736_Generative_Adversarial_Networks_GANs_An_Overview_of_Theoretical_Model_Evaluation_Metrics_and_Recent_Developments"> 그림 출처 </a>
</p>

이렇듯 확률밀도함수를 통해 결과물(여기서는 얼굴)을 **생성**해주는 과정을 샘플링(sampling)이라고 한다.

즉, Generative Model의 목적은 확률분포를 정확히 학습해 좋은 sample을 sampling하는 것이라고 정리할 수 있을 것이다.

## 확률밀도함수를 학습하기 위한 머신 설계

### Boltzmann Machine

Boltzmann Machine은 이렇듯 확률분포(정확히는 확률질량함수 혹은 확률밀도함수)를 학습하기 위해 만들어졌다고 할 수 있다.

Boltzmann Machine이 가정하는 것은 "우리가 보고 있는 것들 외에도 보이지 않는 요소들까지 잘 포함시켜 학습할 수 있다면 확률분포를 좀 더 정확하게 알 수 있지 않을까?"라는 것이다.

<p align = "center">
  <img src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-10-02-RBM/pic3.png">
  <br>
  그림 3. Boltzmann Machine과 Restricted Boltzmann Machine
  <br>
  <a href = "https://www.asimovinstitute.org/neural-network-zoo/"> 그림 출처 </a>
</p>

그림 3의 왼쪽에 보이는 것이 Boltzmann Machine이고 오른쪽에 보이는 것이 Restricted Boltzmann Machine이다.

우선 Boltzmann Machine에 대해서부터 설명하자면 동그랗게 생긴 것들이 가능한 이벤트들에 대한 state이다.

가령, 이 Boltzmann Machine이 얼굴의 형태에 관한 확률밀도함수를 학습하기 위해 만들어졌고, 각 동그라미들은 얼굴의 특정 부위에 대한 상태를 표시한다고 하자.

그 중 하나의 동그라미가 코에 관한 것이고, 상태 0, 1, 2가 동그라미, 세모, 네모 모양의 코에 대한 state를 각각 나타내는 것이라고 할 수 있겠다.

Boltzmann Machine에서 또 하나 주목할 점은 노란색과 초록색으로 표현된 특성인데, 각각은 hidden unit과 visible unit의 존재를 표현한 것이다.

hidden unit이 말하는 것은 우리가 보지 못하는 어떤 특성이 존재함을 암시하고, 이것 까지도 학습할 수 있다면 좀 더 정확한 확률분포를 학습할 수 있다는 것을 전제한다.

### Restricted Boltzmann Machine

그렇다면 우리의 관심사인 Restricted Boltzmann Machine(RBM)은 뭘까?

RBM은 그림 3에서 오른쪽에 표시되어 있는데, RBM은 Boltzmann Machine에서부터 파생되어 나온 것으로 visible unit과 hidden unit에는 내부적인 연결이 없고, visible unit과 hidden unit 간의 연결만이 남아있는 형태이다.

이렇게 RBM을 구성한 것은 상당히 실용적인 이유로 사건 간의 독립성을 가정하면 확률분포의 결합을 표현하기 쉬워지기 때문이다.

쉽게 말하면 Boltzmann Machine의 계산이 너무 복잡해지니까 이를 편하게 하기 위해 덜 엄격한 모델을 구성한 것으로 볼 수 있다.

Boltzmann Machine에서 RBM과 같은 형태를 구성하게 됨으로써 생기는 독특한 점은 RBM은 **Feed-Forward Nerual Network(FFNN) 처럼 학습**하게 된다는 점이다.

뒤에 더 설명하겠지만, RBM의 작동방식은 FFNN과 유사하게 forward propagation을 통해 hidden unit의 상태를 결정하고, 다시 hidden unit의 상태로부터 back propagation을 함으로써 visible unit의 상태를 재결정하게 된다.

그렇지만 RBM을 다루면서도 잊지 않아야 할 것은 결국 RBM도 Boltzmann Machine에서부터 파생된 것으로 현상에 대한 확률분포를 학습하는 Generative Model이라는 점이다.


