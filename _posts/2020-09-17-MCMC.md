---
title: Monte Carlo Markov Chain
sidebar:
  nav: docs-ko
aside:
  toc: true
key: 20200917
tags: 통계학
---

<p align = "center">
  <iframe width = "800" height = "600" src = "https://chi-feng.github.io/mcmc-demo/app.html?algorithm=RandomWalkMH&target=standard" frameborder = "0"></iframe>
  <br>
  <a href = "https://github.com/chi-feng/mcmc-demo"> Interactive MCMC JS Applet by Chi-Feng, 소스코드 </a>
</p>

# prerequisites

이 포스팅에 대해 잘 이해하기 위해선 다음의 내용에 대해 알고 오시는 것이 좋습니다.

* [Rejection Sampling](https://angeloyeo.github.io/2020/09/16/rejection_sampling.html)
* [likelihood의 의미](https://angeloyeo.github.io/2020/07/17/MLE.html)
* [베이즈 정리의 의미](https://angeloyeo.github.io/2020/01/09/Bayes_rule.html)
* [likelihood $\times$ prior의 의미](https://angeloyeo.github.io/2020/08/04/naive_bayes.html)

# MCMC의 정의

위키피디아에 따르면 마르코프 연쇄 몬테카를로 방법(Markov Chain Monte Carlo, MCMC)은 "마르코프 연쇄의 구성에 기반한 확률 분포로부터 원하는 분포의 정적 분포를 갖는 표본을 추출하는 알고리즘의 한 분류이다."라고 나와있다.

복잡해보이지만 우선 MCMC는 샘플링 방법 중 하나인 것이라는 것만 알고있도록 하자. 언제나 그렇듯 정의만 보면 처음 볼 때는 이해할 수 있는 것이 거의 없기에 하나 하나 뜯어서 살펴볼 것이다.

이번 포스팅에서는 복잡한 수학적 내용을 전달하는 것 보다는 MCMC의 의미를 이해할 수 있도록하는데 초점을 맞추고자 한다.

# Monte Carlo

Monte Carlo는 쉽게 말해 통계적인 수치를 얻기 위해 수행하는 '시뮬레이션' 같은 것이다.

굳이 이런 시뮬레이션을 하는 이유는 통계학의 특성 상 무한히 많은 시도를 거쳐야만 진짜 정답이 뭔지 알 수 있지만, 그렇게 하기가 현실적으로 어렵기 때문에 유한한 시도만으로 정답을 추정하자는 데 의미가 있다.

Monte Carlo 방식의 시뮬레이션 중 가장 유명한 것 중 하나가 원의 넓이를 계산하는 시뮬레이션이다.

아래의 그림과 같이 가로, 세로의 길이가 2인 정사각형 안에 점을 무수히 많이 찍으면서, 중심으로부터의 거리가 1이하면 빨간색으로 칠하고, 그렇지 않으면 파란색으로 칠해준다.

전체적으로 찍은 점의 개수와 빨간색으로 찍힌 점의 개수의 비율을 계산하여 원래의 사각형의 면적인 4를 곱해주면 반지름이 1인 원의 넓이를 대략적으로 추정할 수 있다.

<p align = "center">
  <video width = "400" height = "auto" loop autoplay controls muted>
    <source src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-09-17-MCMC/pic1.mp4">
  </video>
  <br>
  그림 1. 반지름이 1인 원의 넓이를 근사적으로 계산하는 Monte Carlo 시뮬레이션
</p>

MCMC에서는 "무수히 뭔가를 많이 시도해본다"는 의미에서 Monte Carlo라는 이름을 붙였다고 보면 좋을 것 같다.

# Markov Chain

Markov Chain은 어떤 상태에서 다른 상태로 넘어갈 때, 바로 전 단계의 상태에만 영향을 받는 확률 과정을 의미한다.

이렇게 들으면 어렵게 들릴 수도 있겠지만, 다음과 같은 비유를 생각해보자.

> 보통 사람들은 전날 먹은 식사와 유사한 식사를 하지 않으려는 경향이 있다.
> 
> 가령, 어제 짜장면을 먹었다면 오늘은 면종류의 음식을 먹으려고 하지 않는다.

이렇듯 음식 선택이라는 확률과정에 대해 오늘의 음식 선택이라는 과정은 어제의 음식 선택에만 영향을 받고, 그저께의 음식 선택에는 영향을 받지 않는다면

이 과정은 마르코프 성질(Markov property)을 가진다고 할 수 있으며, 이 확률 과정은 Markov chain이라고 할 수 있다.

앞서 MCMC는 샘플링 방법 중 하나라고 하였는데, "가장 마지막에 뽑힌 샘플이 다음번 샘플을 추천해준다"는 의미에서 Markov Chain이라는 단어가 들어갔다고 보면 좋을 것 같다.

# Monte Carlo Markov Chain

MCMC는 Monte Carlo와 Markov Chain의 개념을 합친 것이다.

다시 말해 MCMC를 수행한다는 것은 첫 샘플을 랜덤하게 선정한 뒤, 첫 샘플에 의해 그 다음번 샘플이 추천되는 방식의 시도를 무수하게 해본다는 의미를 갖고 있다.

위의 문장에서 가장 수학적이지 않은 단어는 뭘까? 바로 "추천"이다.

또, 추천 다음에는 "승낙/거절"의 단계까지도 포함되는데, 이 과정에 대해 알아보도록 하자.

## 샘플링 과정

우선은 [Rejection Sampling]을 할 때와 마찬가지로 target 분포가 하나 있어야 한다.





# 참고자료


* An introduction to MCMC for Maching Learning / C. Andrieu et al., Machine Learning, 50, 5-43, 2003
* [서울대학교 통계학과 김용대 교수님의 강의노트](https://stat.snu.ac.kr/ydkim/courses/2017-1/addm/MCM-Slide.pdf)
* Joseph Moukarzel의 포스팅 [From Scratch: Bayesian Inference, Markov Chain Monte Carlo and Metropolis Hastings, in python](https://github.com/Joseph94m/MCMC/blob/master/MCMC.ipynb)을 참고하여 작성하였습니다.