---
title: Monte Carlo Markov Chain
sidebar:
  nav: docs-ko
aside:
  toc: true
key: 20200917
tags: 통계학
---

본 포스팅은 [서울대학교 통계학과 김용대 교수님의 강의노트](https://stat.snu.ac.kr/ydkim/courses/2017-1/addm/MCM-Slide.pdf)와 Joseph Moukarzel의 포스팅 [From Scratch: Bayesian Inference, Markov Chain Monte Carlo and Metropolis Hastings, in python](https://github.com/Joseph94m/MCMC/blob/master/MCMC.ipynb)을 참고하여 작성하였습니다.

# prerequisites

이 포스팅에 대해 잘 이해하기 위해선 다음의 내용에 대해 알고 오시는 것이 좋습니다.

* [베이즈 정리의 의미](https://angeloyeo.github.io/2020/01/09/Bayes_rule.html)
* [likelihood의 의미](https://angeloyeo.github.io/2020/07/17/MLE.html)
* [likelihood $\times$ prior의 의미](https://angeloyeo.github.io/2020/08/04/naive_bayes.html)

<p align = "center">
  <iframe width = "800" height = "600" src = "https://chi-feng.github.io/mcmc-demo/app.html?algorithm=RandomWalkMH&target=standard" frameborder = "0"></iframe>
  <br>
  <a href = "https://github.com/chi-feng/mcmc-demo"> Interactive MCMC JS Applet by Chi-Feng, 소스코드 </a>
</p>

# MCMC의 정의

# Monte Carlo

실제로는 무한히 많은 시도가 필요하지만, 유한한 데이터를 이용해 근사적인 해를 구할 수 있음.

<p align = "center">
  <video width = "400" height = "auto" loop autoplay controls muted>
    <source src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-09-17-MCMC/pic1.mp4">
  </video>
  <br>
  그림 1. 반지름이 1인 원의 넓이를 근사적으로 계산하는 Monte Carlo 시뮬레이션
</p>

랜덤변수 $x$의 확률밀도함수가 $f(x)$일 때의 기댓값

$$E[X]=\int_{-\infty}^{\infty} xf(x)dx$$

하지만, 독립적인 샘플을 N개 뽑아서 근사적으로 기댓값을 계산할 수 있다.

$$E[X] \approx \frac{1}{N}\sum_{i=1}^{N}x_i$$

# Markov Chain

Markov Chain은 ~

A sequence of random varialbes $X_0, X_1, X_2, \cdots$ 은 아래의 조건을 만족한다면 Markov Chain이라 할 수 있다.

$$p(X_t|X_0, \cdots, X_{t-1}) = p(X_t|X_{t-1})$$

점심을 짜장면을 먹었다고 하면 저녁에는 면종류의 식사를 잘 하지 않는다.

오늘은 어제의 내일이다.?

# Monte Carlo Markov Chain

MCMC는 Monte Carlo와 Markov Chain의 개념을 합친 것.


# MLE 와 비교 시

? 어떤게 다를까?

