---
title: Monte Carlo Markov Chain
sidebar:
  nav: docs-ko
aside:
  toc: true
key: 20200917
tags: 통계학
---

<p align = "center">
  <iframe width = "800" height = "600" src = "https://chi-feng.github.io/mcmc-demo/app.html?algorithm=RandomWalkMH&target=standard" frameborder = "0"></iframe>
  <br>
  <a href = "https://github.com/chi-feng/mcmc-demo"> Interactive MCMC JS Applet by Chi-Feng, 소스코드 </a>
</p>

# prerequisites

이 포스팅에 대해 잘 이해하기 위해선 다음의 내용에 대해 알고 오시는 것이 좋습니다.

* [Rejection Sampling](https://angeloyeo.github.io/2020/09/16/rejection_sampling.html)
* [likelihood의 의미](https://angeloyeo.github.io/2020/07/17/MLE.html)

# MCMC의 정의

위키피디아에 따르면 마르코프 연쇄 몬테카를로 방법(Markov Chain Monte Carlo, MCMC)은 "마르코프 연쇄의 구성에 기반한 확률 분포로부터 원하는 분포의 정적 분포를 갖는 표본을 추출하는 알고리즘의 한 분류이다."라고 나와있다.

복잡해보이지만 우선 MCMC는 샘플링 방법 중 하나인 것이라는 것만 알고있도록 하자. 언제나 그렇듯 정의만 보면 처음 볼 때는 이해할 수 있는 것이 거의 없기에 하나 하나 뜯어서 살펴볼 것이다.

이번 포스팅에서는 복잡한 수학적 내용을 전달하는 것 보다는 MCMC의 의미를 이해할 수 있도록하는데 초점을 맞추고자 한다.

# Monte Carlo

Monte Carlo는 쉽게 말해 통계적인 수치를 얻기 위해 수행하는 '시뮬레이션' 같은 것이다.

굳이 이런 시뮬레이션을 하는 이유는 통계학의 특성 상 무한히 많은 시도를 거쳐야만 진짜 정답이 뭔지 알 수 있지만, 그렇게 하기가 현실적으로 어렵기 때문에 유한한 시도만으로 정답을 추정하자는 데 의미가 있다.

Monte Carlo 방식의 시뮬레이션 중 가장 유명한 것 중 하나가 원의 넓이를 계산하는 시뮬레이션이다.

아래의 그림과 같이 가로, 세로의 길이가 2인 정사각형 안에 점을 무수히 많이 찍으면서, 중심으로부터의 거리가 1이하면 빨간색으로 칠하고, 그렇지 않으면 파란색으로 칠해준다.

전체적으로 찍은 점의 개수와 빨간색으로 찍힌 점의 개수의 비율을 계산하여 원래의 사각형의 면적인 4를 곱해주면 반지름이 1인 원의 넓이를 대략적으로 추정할 수 있다.

<p align = "center">
  <video width = "400" height = "auto" loop autoplay controls muted>
    <source src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-09-17-MCMC/pic1.mp4">
  </video>
  <br>
  그림 1. 반지름이 1인 원의 넓이를 근사적으로 계산하는 Monte Carlo 시뮬레이션
</p>

MCMC에서는 "통계적인 특성을 이용해 무수히 뭔가를 많이 시도해본다"는 의미에서 Monte Carlo라는 이름을 붙였다고 보면 좋을 것 같다.

# Markov Chain

Markov Chain은 어떤 상태에서 다른 상태로 넘어갈 때, 바로 전 단계의 상태에만 영향을 받는 확률 과정을 의미한다.

이렇게 들으면 어렵게 들릴 수도 있겠지만, 다음과 같은 비유를 생각해보자.

> 보통 사람들은 전날 먹은 식사와 유사한 식사를 하지 않으려는 경향이 있다.
> 
> 가령, 어제 짜장면을 먹었다면 오늘은 면종류의 음식을 먹으려고 하지 않는다.

이렇듯 음식 선택이라는 확률과정에 대해 오늘의 음식 선택이라는 과정은 어제의 음식 선택에만 영향을 받고, 그저께의 음식 선택에는 영향을 받지 않는다면

이 과정은 마르코프 성질(Markov property)을 가진다고 할 수 있으며, 이 확률 과정은 Markov chain이라고 할 수 있다.

앞서 MCMC는 샘플링 방법 중 하나라고 하였는데, "가장 마지막에 뽑힌 샘플이 다음번 샘플을 추천해준다"는 의미에서 Markov Chain이라는 단어가 들어갔다고 보면 좋을 것 같다.

# MCMC를 이용한 샘플링

MCMC는 Monte Carlo와 Markov Chain의 개념을 합친 것이다.

다시 말해 MCMC를 수행한다는 것은 첫 샘플을 랜덤하게 선정한 뒤, 첫 샘플에 의해 그 다음번 샘플이 추천되는 방식의 시도를 무수하게 해본다는 의미를 갖고 있다.

위의 문장에서 가장 수학적이지 않은 단어는 뭘까? 바로 "추천"이다.

또, 추천 다음에는 "승낙/거절"의 단계까지도 포함되는데, 이 과정에 대해 알아보도록 하자.

참고로 이 post에서 주요하게 소개하는 MCMC 샘플링 알고리즘은 Metropolis 알고리즘이다.

## 샘플링 과정 (Metropolis 알고리즘)

우선은 [Rejection Sampling](https://angeloyeo.github.io/2020/09/16/rejection_sampling.html)을 할 때와 마찬가지로 샘플을 추출하고자 하는 target 분포가 하나 있어야 한다.

이 타겟 분포는 정확히는 확률밀도 함수가 아니어도 괜찮다. 대략적으로 확률밀도 함수의 크기에 비례하는 함수를 이용하면 충분하다.

가령 아래와 같은 함수를 타겟 분포로 사용할 수 있다. 

$$f(x) = 0.3\exp\left(-0.2x^2\right) + 0.7\exp\left(-0.2(x-10)^2\right)$$

[//]:# (수식 1)

이 함수는 $-\infty$부터 $\infty$까지의 전체 면적이 1이 아니기 때문에 확률밀도 함수라고 할수는 없다. 하지만, 만약 우리가 실험적인 결과로 확률밀도함수가 대략적으로 타겟 함수 $f(x)$와 비슷한 형태를 띄고 있다는 것을 알고 있다면 우리는 이러한 타겟 함수로부터 실제 확률밀도함수를 근사하기 위해 샘플링이 필요할 수 있다.

### 1. random initialization

MCMC의 샘플링 과정에서 가장 먼저 수행해줄 것은 random initialization이다.

쉽게 말해 샘플 공간에서 아무런 입력값이나 하나를 선택해 주는 것이다.

가령 아래의 그림과 같이 $x_0$를 임의로 선택할 수 있다.

아래 그림에서는 $x_0 = 7$로 설정해보았다.

<p align = "center">
  <img src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-09-17-MCMC/pic2.png">
  <br>
  그림 2. target 분포와는 크게 관계없이 임의의 시작 포인트를 선택하여 MCMC 알고리즘을 시작한다.
</p>

### 2. 제안 분포로부터 다음 포인트를 추천받기

MCMC의 그 다음번 스텝은 제안 분포로부터 다음번으로 추출해볼 샘플을 추천받는 것이다.

제안분포는 어떤 확률분포를 이용해도 상관없으나, Metropolis는 symmetric한 확률분포를 사용하는 경우에 대한 알고리즘을 제안했고, Hastings는 일반적인 확률 분포에 대한 경우까지 어떻게 수학적으로 계산할 수 있는지에 관해 Metropolis가 제안한 알고리즘을 확장하였다.

우리는 논의를 쉽게 하기 위해서 symmetric한 확률분포를 제안분포로 사용해보도록 하자.

여기서 제안분포는 $g(x)$라고 부르도록 하자.

보통 symmetric한 제안분포로 많이 사용되는 확률분포는 예상했겠지만 정규분포이다.

그러면, 처음 시작으로 잡은 $x_0$를 중심으로 정규분포를 하나 그려본다.

이 때, 정규분포의 너비(즉, 표준 편차)는 연구자의 선택에 따라 임의로 설정하면 된다.

이번 그림에서는 표준편차를 2로 설정해보았다.

<p align = "center">
  <img src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-09-17-MCMC/pic3.png">
  <br>
  그림 3. 시작점에서 제안 분포를 형성하자.
</p>

잘 생각해보면 우리의 제안 분포는 정규분포인데 평균이 7이고 표준편차가 2이다.

이런 정규분포에서는 샘플을 추출하기가 쉽다. MATLAB에서는 randn()함수를 이용해서 쉽게 표본을 추출할 수 있다.

아래와 같이 제안 분포로부터 다음 포인트를 추천받아보자.

<p align = "center">
  <img src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-09-17-MCMC/pic4.png">
  <br>
  그림 4. 제안분포로부터 다음 포인트를 추천 받았을 때 어떤 경우는 추천을 거절하고, 어떤 경우는 추천을 수용한다.
</p>

그림 4를 보면 파란색 점으로 표시한 것들이 새롭게 제안된 샘플 포인트와 그 포인트에서의 타겟 분포의 값을 표현하였다.

또, 그림 4를 잘 보면 왼쪽 그림에서 제안된 새로운 샘플 포인트는 거절됐고, 오른쪽 그림에서 제안된 새로운 샘플 포인트는 수용되었다.

거절의 이유는 타겟 분포에서의 높이가 원래의 $x_0$에서의 높이보다 제안된 샘플 포인트의 타겟 분포의 높이보다 낮아서이고,

수용의 이유는 반대로 타겟 분포에서의 높이가 원래의 $x_0$에서의 높이보다 제안된 샘플 포인트의 타겟 분포에서의 높이보다 높아서이다.

즉, 다음의 기준에 따라 수용 여부를 결정한다.

$$\frac{f(x_1)}{f(x_0)}>1?$$

[//]:# (수식 2)


만약, 제안이 수용되었다면 수용된 샘플 포인트를 중심으로 제안 분포를 그리고 이를 통해 샘플을 또 추천받아본다.

그런데, 제안이 수용되지 않았다면 통계적으로 수용하게끔 MCMC는 패자부활전을 마련해놓았다.

### 3. 패자부활전

앞서 2번 단계에서 거절된 샘플들은 무조건 이용하지 않는 것은 아니고 통계적으로 수용할 수 있게 만들어놓았다.

원래의 샘플의 위치를 $x_0$라고 하고 제안 분포를 통해 새로 제안 받은 샘플의 위치를 $x_1$이라고 하자.

이 때, target 분포를 지금까지 처럼 $f(x)$라고 하면 다음에 대해 확인해본다.

uniform distribution $U_{(0,1)}$에서 부터 추출한 임의의 샘플 $u$에 대해서,

$$\frac{f(x_1)}{f(x_0)}>u$$

[//]:# (수식 3)

만약 수식 (3)이 만족되면, 이 샘플은 비록 타겟 분포에서 새로운 샘플에 대한 높이가 더 높지는 않았지만 수용하게 된다.

만약 여기서도 수식 (3)을 만족하지 못하면 그 때는 새로운 샘플 $x_1$을 샘플링하기를 수용하지 않고, $x_1$을 $x_0$으로 설정한 뒤 다음 샘플($x_2$)을 추천 받는다.

이와 같은 2~3의 단계를 계속 수행해나가면 된다.

## 알고리즘의 pseudo-code

여기까지가 MCMC 알고리즘의 끝이다. 정말 간단하다.

이 내용을 pseudo-code로 작성하면 다음과 같다.

> 1. Initialize $x_0$
>
> 2. For $i=0$ to $N-1$
> 
>Sample $u\sim U_{[0,1])}$
>
>Sample $x_{new}~g(x_{new}\|x_i))$
>
>If $u\lt A(x_i, x_{new}) = min\left\lbrace 1, f(x_{new})/f(x_i)\right\rbrace$
> 
>$\quad x_{i+1} = x_{new}$
>
>else
> 
>$\quad x_{i+1} = x_i$

## 제안 분포가 symmetric 하지 않은 경우는?

위의 샘플링 과정 전체를 통틀어 제안 분포가 symmetric 하지 않은 경우에 관한 알고리즘이 Metropolis 알고리즘을 업그레이드한 Metropolis-Hastings 알고리즘이다.

Metropolis-Hastings 알고리즘에서는 수식 (2)에서 보였던 타겟 분포의 likelihood 비교 시에 제안 분포의 높이도 함께 이용해 그 값을 보정해주어야 한다.

즉, 수식 (2)의 기준은 다음과 같이 보정될 수 있다.

제안 분포를 $g(x)$라고 할 때,

$$수식(2) \Rightarrow 
  \frac{f(x_1)/g(x_1|x_0)}
  {f(x_0)/g(x_0|x_1)}$$

[//]:# (수식 4)


다시 말해 수식 (4)의 분자를 보면 새로운 포인트 $x_1$에 대해서는 $x_0$를 기준으로 뽑은 $g(x_1\|x_0)$ 값을 이용해 정규화 해주고,

또, 이전의 포인트 $x_0$에 대해서는 새로운 $x_1$을 기준으로 $g(x_0\|x_1)$의 값을 이용해 정규화 해주었다고 볼 수 있다.

## 샘플링 결과

위에서 설명한 Metropolis 알고리즘을 이용해 샘플링을 하면 아래와 같은 결과를 얻을 수 있다.

<p align = "center">
  <img src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-09-17-MCMC/pic5.png">
  <br>
  그림 5. MCMC 알고리즘을 이용해 샘플링한 결과
</p>

# MCMC를 이용한 Bayesian Inference

샘플링 뿐만 아니라 MCMC는 파라미터 추정에도 사용될 수 있다.

## prerequisites

이 내용에 대해 잘 이해하시려면 다음의 내용에 대해 알고 오시는 것을 추천드립니다.

* [베이즈 정리의 의미](https://angeloyeo.github.io/2020/01/09/Bayes_rule.html)
* [likelihood $\times$ prior의 의미](https://angeloyeo.github.io/2020/08/04/naive_bayes.html)


# 참고자료


* An introduction to MCMC for Maching Learning / C. Andrieu et al., Machine Learning, 50, 5-43, 2003
* [서울대학교 통계학과 김용대 교수님의 강의노트](https://stat.snu.ac.kr/ydkim/courses/2017-1/addm/MCM-Slide.pdf)
* Joseph Moukarzel의 포스팅 [From Scratch: Bayesian Inference, Markov Chain Monte Carlo and Metropolis Hastings, in python](https://github.com/Joseph94m/MCMC/blob/master/MCMC.ipynb)을 참고하여 작성하였습니다.