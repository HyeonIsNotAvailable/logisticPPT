---
title: Variational AutoEncoder
sidebar:
  nav: docs-ko
aside:
  toc: true
key: 20201011
tags: 기계학습
---

※ 이 포스팅은 미술관에 GAN 딥러닝 실전 프로젝트의 결과와 소스 코드를 이용해 작성한 것임을 밝힙니다.

※ 이 포스팅의 소스 코드는 박해선 님의 깃허브 레포에서 확인하실 수 있습니다.

# Prerequisites

해당 포스팅을 이해하기 위해선 다음의 내용에 대해 알고 오시는 것을 추천드립니다.

* [AutoEncoder](https://angeloyeo.github.io/2020/10/10/autoencoder.html)
* [정보 엔트로피](https://angeloyeo.github.io/2020/10/26/information_entropy.html)
* [KL divergence](https://angeloyeo.github.io/2020/10/27/KL_divergence.html)

# 오토 인코더 짧게 복습

Variational AutoEncoder(VAE)는 기본적으로 AutoEncoder(AE)의 형태를 그대로 유지하고 있다.

따라서, VAE를 잘 이해하기 위해선 AE의 특성을 잘 파악하고, 어떤 부분에서 AE의 한계점이 있으며, 그 한계점들을 극복하기 위해 VAE는 어떤 보완책들을 내놓았는지 알아볼 필요가 있다.

[AutoEncoder](https://angeloyeo.github.io/2020/10/10/autoencoder.html)편의 내용을 짧게 복습해보자.

기본적으로 AE는 데이터를 압축하고 압축 해제하는 과정을 거치게 만든 뉴럴네트워크이다.

<p align ="center">
  <img width = "400" src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-10-10-autoencoder/pic1.png">
  <br>
  그림 1. 오토인코더의 구조와 역할
</p>

이 때, 데이터를 압축해 얻어낸 새로운 종류의 벡터를 '표현 벡터(representation vector)' 혹은 latent factor라고 부른다.

가령, 28*28 = 784 차원인 MNIST 데이터셋을 이용해 2차원 표현 벡터를 얻게 된다고 하면 다음과 같이 2차원 평면 상에 label을 붙여 표현해 볼 수 있다.

<p align ="center">
  <img width = "400" src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-10-10-autoencoder/pic3.png">
  <br>
  그림 2. MNIST 데이터의 representation vector의 시각화
</p>

여기까지의 "압축" 과정을 통해 고차원 데이터를 저차원으로 변환시켜주는 과정을 "인코딩"이라고 하고, 이러한 일을 수행하는 뉴럴네트워크 부(部)를 "인코더"라고 부른다.

뿐만 아니라 AE는 "압축해제"를 수행할 수도 있는데, 